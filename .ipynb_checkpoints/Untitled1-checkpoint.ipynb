{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer.csv', encoding = \"ISO-8859-1\")\n",
    "dl = df['text'].tolist()\n",
    "mytext = \" \".join(str(x) for x in dl)\n",
    "#print(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word  frequency\n",
      "0             .      22183\n",
      "1             ,      16942\n",
      "2             I      13321\n",
      "3        cancer       2661\n",
      "4             ?       2158\n",
      "5           n't       2124\n",
      "6             )       2100\n",
      "7             (       2069\n",
      "8             !       1756\n",
      "9           ...       1659\n",
      "10           's       1606\n",
      "11         know       1429\n",
      "12        would       1342\n",
      "13          The       1301\n",
      "14          one       1079\n",
      "15        chemo       1056\n",
      "16           ''       1027\n",
      "17           It       1007\n",
      "18           ``        996\n",
      "19          get        988\n",
      "20    treatment        982\n",
      "21       breast        949\n",
      "22           'm        943\n",
      "23         like        929\n",
      "24         time        928\n",
      "25           My        921\n",
      "26         good        865\n",
      "27          Leo        839\n",
      "28         also        789\n",
      "29            :        778\n",
      "..          ...        ...\n",
      "170      taking        240\n",
      "171    question        240\n",
      "172        left        239\n",
      "173          ca        238\n",
      "174      always        238\n",
      "175         ask        237\n",
      "176        read        236\n",
      "177           %        235\n",
      "178        lung        235\n",
      "179        site        234\n",
      "180     started        234\n",
      "181           5        231\n",
      "182     thought        231\n",
      "183        lump        230\n",
      "184        keep        229\n",
      "185        body        229\n",
      "186        hear        229\n",
      "187        come        225\n",
      "188     results        225\n",
      "189      little        225\n",
      "190         And        224\n",
      "191       liver        221\n",
      "192        scan        219\n",
      "193        next        219\n",
      "194    problems        216\n",
      "195         're        215\n",
      "196         try        214\n",
      "197        node        213\n",
      "198        hair        213\n",
      "199  mastectomy        212\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "content = pd.DataFrame([])\n",
    "\n",
    "#.replace('|',' ')\n",
    "\n",
    "stemtext = ps.stem(mytext)\n",
    "tokens = nltk.word_tokenize(mytext)\n",
    "\n",
    "tokensf = []\n",
    "\n",
    "for w in tokens:\n",
    "    if w not in stopWords:\n",
    "        tokensf.append(w)\n",
    "\n",
    "frequencies = FreqDist(tokensf).most_common(200)\n",
    "frequenciesdf = pd.DataFrame(frequencies, columns=['word','frequency'])\n",
    "print(frequenciesdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "#vec = TfidfVectorizer(token_pattern=r'(?<=[^|;])[\\s\\w]+(?=[$|;])')\n",
    "X = vec.fit_transform(dl)\n",
    "#print(pd.DataFrame(X.toarray(), columns=vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xfr = pd.DataFrame(X.toarray())\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA =  PCA(n_components=60) \n",
    "XPCA = PCA.fit_transform(Xfr)\n",
    "dPCA = pd.DataFrame(XPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
